# -*- coding: utf-8 -*-
"""train.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1bVam9IVEPoJAlae-6oT400qQ0RNm2Va_
"""



import numpy as np 
import pandas as pd 

from sklearn import preprocessing
from sklearn.model_selection import train_test_split

import keras

from sklearn.linear_model import LinearRegression
from sklearn.metrics import r2_score
import xgboost

from sklearn.model_selection import RandomizedSearchCV

"""# Loading Data and Separating Features and Labels"""

df = pd.read_csv('/content/trainingdata.csv' , names = range(46))              #  loading Training Data          # please paste training data path between Single Quotation Marks (‘ ’) like'.....Paste Here.....' 
                #'....Training data path..'  
df = df.reset_index()
df = df.drop('index' ,axis =1)                                                                           
df

df_copy = df.drop(columns = 45)             # features

df_copy

dfy = df[45]           # labels

dfy

x = df_copy.values            #converting to  ndarray

y = dfy.values                #converting to  ndarray

#x_train , x_test , y_train , y_test = train_test_split(x,y , test_size=0.3 , random_state= 0 )

"""# Training the Model"""

params = { 'max_depth': [3, 5, 6, 10, 15, 20],
           'learning_rate': [0.01, 0.1, 0.2, 0.3],                           #Hyperparameters
           'subsample': np.arange(0.5, 1.0, 0.1),
           'colsample_bytree': np.arange(0.4, 1.0, 0.1),
           'colsample_bylevel': np.arange(0.4, 1.0, 0.1),
           'n_estimators': [100, 500, 1000]}

xgbr = xgboost.XGBRegressor(seed = 20)

clf = RandomizedSearchCV(estimator=xgbr,
                         param_distributions=params,
                         scoring='neg_mean_squared_error',
                         n_iter=25,
                         verbose=1)

clf.fit(x,y)                                                                  #Model training

print("Best parameters:", clf.best_params_)
print("Lowest RMSE: ", (-clf.best_score_)**(1/2.0))

"""# Saving the model in a pickle file for further use"""

from joblib import Parallel, delayed
import joblib
  
  
                                                            
joblib.dump(clf, 'Multiple_Regression_Topcoder.pkl')            # Save the model as a pickle in a file